Export Configuration:
{
  "repo_root": ".",
  "export_name": "._export.txt",
  "delimiter": "---",
  "dirs_to_traverse": [
    "."
  ],
  "include_top_level_files": "all",
  "included_extensions": "all",
  "subdirs_to_exclude": [
    "__pycache__"
  ],
  "files_to_exclude": [
    "._export.txt"
  ],
  "depth": 10,
  "exhaustive_dir_tree": false,
  "blacklisted_dirs": [
    "__pycache__"
  ],
  "files_to_include": [],
  "output_file": "./._export.txt",
  "exported_files_count": {},
  "total_lines": 0
}
Directory tree, stemming from root ".":
├── ._export.txt
├── geom.sh
├── ingest.sh
└── vers_origin.sh

---
Full Path: vers_origin.sh

#!/bin/bash

# Function to run the update in parallel
run_update() {
  local TABLE_NAME=$1
  local COLUMN_NAME=$2
  local VALUE=$3
  local OFFSET=$4
  local LIMIT=$5
  local DB_NAME=$6

  docker exec ibrida psql -U postgres -d "${DB_NAME}" -c "
  UPDATE ${TABLE_NAME}
  SET ${COLUMN_NAME} = '${VALUE}'
  WHERE ctid IN (
    SELECT ctid
    FROM ${TABLE_NAME}
    ORDER BY ctid
    OFFSET ${OFFSET}
    LIMIT ${LIMIT}
  );"
}

# Check if correct number of arguments are provided
if [ "$#" -ne 5 ]; then
  echo "Usage: $0 <database_name> <num_workers> <origin_value> <version_value>"
  exit 1
fi

# Define arguments
DB_NAME=$1
NUM_PROCESSES=$2
ORIGIN_VALUE=$3
VERSION_VALUE=$4

# Tables and their columns to update
declare -A TABLES_COLUMNS
TABLES_COLUMNS=(
  ["taxa"]="origin,version"
  ["observers"]="origin,version"
  ["observations"]="origin,version"
  ["photos"]="origin,version"
)

# Function to update columns in parallel
update_columns_in_parallel() {
  local TABLE_NAME=$1
  local COLUMN_NAME=$2
  local VALUE=$3
  local TOTAL_ROWS
  TOTAL_ROWS=$(docker exec ibrida psql -U postgres -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM ${TABLE_NAME};")
  local BATCH_SIZE=$((TOTAL_ROWS / NUM_PROCESSES))

  for ((i=0; i<NUM_PROCESSES; i++)); do
    local OFFSET=$((i * BATCH_SIZE))
    run_update ${TABLE_NAME} ${COLUMN_NAME} ${VALUE} ${OFFSET} ${BATCH_SIZE} ${DB_NAME} &
  done
}

# Update columns in parallel
for TABLE_NAME in "${!TABLES_COLUMNS[@]}"; do
  IFS=',' read -ra COLUMNS <<< "${TABLES_COLUMNS[$TABLE_NAME]}"
  for COLUMN in "${COLUMNS[@]}"; do
    if [ "$COLUMN" == "origin" ]; then
      update_columns_in_parallel "$TABLE_NAME" "$COLUMN" "$ORIGIN_VALUE"
    elif [ "$COLUMN" == "version" ]; then
      update_columns_in_parallel "$TABLE_NAME" "$COLUMN" "$VERSION_VALUE"
    fi
  done
done

# Wait for all processes to finish
wait
echo "All updates completed."


---
Full Path: ingest.sh

#!/bin/bash

# Database and user variables
DB_USER="postgres"
DB_TEMPLATE="template_postgis"
NUM_PROCESSES=16
BASE_DIR="/home/caleb/repo/ibridaDB/dbTools/ingest/v0"

# Source variable
SOURCE="June2024"

# Construct origin value based on source
ORIGIN_VALUE="iNat-${SOURCE}"

# Version variable
VERSION_VALUE="v0"

# Construct database name
DB_NAME="ibrida-${VERSION_VALUE}"

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec ibrida psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Create database, drop if exists
print_progress "Creating database"
docker exec ibrida psql -U "$DB_USER" -c "DROP DATABASE IF EXISTS \"$DB_NAME\";"
docker exec ibrida psql -U "$DB_USER" -c "CREATE DATABASE \"$DB_NAME\" WITH TEMPLATE $DB_TEMPLATE OWNER $DB_USER;"

# Connect to the database and create tables
print_progress "Creating tables"
execute_sql "
BEGIN;

CREATE TABLE observations (
    observation_uuid uuid NOT NULL,
    observer_id integer,
    latitude numeric(15,10),
    longitude numeric(15,10),
    positional_accuracy integer,
    taxon_id integer,
    quality_grade character varying(255),
    observed_on date
);

CREATE TABLE photos (
    photo_uuid uuid NOT NULL,
    photo_id integer NOT NULL,
    observation_uuid uuid NOT NULL,
    observer_id integer,
    extension character varying(5),
    license character varying(255),
    width smallint,
    height smallint,
    position smallint
);

CREATE TABLE taxa (
    taxon_id integer NOT NULL,
    ancestry character varying(255),
    rank_level double precision,
    rank character varying(255),
    name character varying(255),
    active boolean
);

CREATE TABLE observers (
    observer_id integer NOT NULL,
    login character varying(255),
    name character varying(255)
);

COMMIT;
"

# Import data
print_progress "Importing data"
execute_sql "
BEGIN;

COPY observations FROM '/metadata/${SOURCE}/observations.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY photos FROM '/metadata/${SOURCE}/photos.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY taxa FROM '/metadata/${SOURCE}/taxa.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY observers FROM '/metadata/${SOURCE}/observers.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;

COMMIT;
"

# Create indexes
print_progress "Creating indexes"
execute_sql "
BEGIN;

CREATE INDEX index_photos_photo_uuid ON photos USING btree (photo_uuid);
CREATE INDEX index_photos_observation_uuid ON photos USING btree (observation_uuid);
CREATE INDEX index_photos_position ON photos USING btree (position);
CREATE INDEX index_photos_photo_id ON photos USING btree (photo_id);
CREATE INDEX index_taxa_taxon_id ON taxa USING btree (taxon_id);
CREATE INDEX index_observers_observers_id ON observers USING btree (observer_id);
CREATE INDEX index_observations_observer_id ON observations USING btree (observer_id);
CREATE INDEX index_observations_quality ON observations USING btree (quality_grade);
CREATE INDEX index_observations_taxon_id ON observations USING btree (taxon_id);
CREATE INDEX index_taxa_active ON taxa USING btree (active);
CREATE INDEX index_observations_taxon_id ON observations USING btree (taxon_id);

COMMIT;
"

# Add geom column (parallelized calculation using geom.sh)
print_progress "Adding geom column"
execute_sql "ALTER TABLE observations ADD COLUMN geom public.geometry;"

# Run parallel geom calculations
print_progress "Running parallel geom calculations"
"${BASE_DIR}/geom.sh" "$DB_NAME" "observations" "$NUM_PROCESSES" "$BASE_DIR"

# Create geom index
print_progress "Creating geom index"
execute_sql "
BEGIN;

CREATE INDEX observations_geom ON observations USING GIST (geom);

COMMIT;
"

# Vacuum analyze
print_progress "Vacuum analyze"
execute_sql "VACUUM ANALYZE;"

# Add origin and version columns in parallel
print_progress "Adding origin and version columns"
execute_sql "
BEGIN;

ALTER TABLE taxa ADD COLUMN origin VARCHAR(255);
ALTER TABLE observers ADD COLUMN origin VARCHAR(255);
ALTER TABLE observations ADD COLUMN origin VARCHAR(255);
ALTER TABLE photos ADD COLUMN origin VARCHAR(255);
ALTER TABLE photos ADD COLUMN version VARCHAR(255);
ALTER TABLE observations ADD COLUMN version VARCHAR(255);
ALTER TABLE observers ADD COLUMN version VARCHAR(255);
ALTER TABLE taxa ADD COLUMN version VARCHAR(255);

COMMIT;
"

# Run parallel updates for origin and version columns
print_progress "Running parallel updates for origin and version columns"
"${BASE_DIR}/vers_origin.sh" "$DB_NAME" "$NUM_PROCESSES" "$ORIGIN_VALUE" "$VERSION_VALUE"

# Create indexes for origin and version columns
print_progress "Creating indexes for origin and version columns"
execute_sql "
BEGIN;

CREATE INDEX index_taxa_origins ON taxa USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_taxa_name ON taxa USING GIN (to_tsvector('simple', name));
CREATE INDEX index_observers_origins ON observers USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_observations_origins ON observations USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_photos_origins ON photos USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_photos_version ON photos USING GIN (to_tsvector('simple', version));
CREATE INDEX index_observations_version ON observations USING GIN (to_tsvector('simple', version));
CREATE INDEX index_observers_version ON observers USING GIN (to_tsvector('simple', version));
CREATE INDEX index_taxa_version ON taxa USING GIN (to_tsvector('simple', version));

COMMIT;
"

print_progress "Database setup complete"


---
Full Path: geom.sh

#!/bin/bash

# Function to run the update in parallel
run_update() {
  local OFFSET=$1
  local LIMIT=$2
  local DB_NAME=$3
  local TABLE_NAME=$4

  docker exec ibrida psql -U postgres -d "${DB_NAME}" -c "
  UPDATE ${TABLE_NAME}
  SET geom = ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)::public.geometry
  WHERE observation_uuid IN (
    SELECT observation_uuid
    FROM ${TABLE_NAME}
    ORDER BY observation_uuid
    OFFSET ${OFFSET}
    LIMIT ${LIMIT}
  );"
}

# Check if correct number of arguments are provided
if [ "$#" -ne 4 ]; then
  echo "Usage: $0 <database_name> <table_name> <num_workers> <base_dir>"
  exit 1
fi

# Define arguments
DB_NAME=$1
TABLE_NAME=$2
NUM_PROCESSES=$3
BASE_DIR=$4

# Calculate total rows and batch size
TOTAL_ROWS=$(docker exec ibrida psql -U postgres -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM ${TABLE_NAME};")
BATCH_SIZE=$((TOTAL_ROWS / NUM_PROCESSES))

# Run updates in parallel
for ((i=0; i<NUM_PROCESSES; i++)); do
  OFFSET=$((i * BATCH_SIZE))
  run_update ${OFFSET} ${BATCH_SIZE} ${DB_NAME} ${TABLE_NAME} &
done

# Wait for all processes to finish
wait
echo "All updates completed."


---
Full Path: vers_origin.sh

#!/bin/bash

# Function to run the update in parallel
run_update() {
  local TABLE_NAME=$1
  local COLUMN_NAME=$2
  local VALUE=$3
  local OFFSET=$4
  local LIMIT=$5
  local DB_NAME=$6

  docker exec ibrida psql -U postgres -d "${DB_NAME}" -c "
  UPDATE ${TABLE_NAME}
  SET ${COLUMN_NAME} = '${VALUE}'
  WHERE ctid IN (
    SELECT ctid
    FROM ${TABLE_NAME}
    ORDER BY ctid
    OFFSET ${OFFSET}
    LIMIT ${LIMIT}
  );"
}

# Check if correct number of arguments are provided
if [ "$#" -ne 5 ]; then
  echo "Usage: $0 <database_name> <num_workers> <origin_value> <version_value>"
  exit 1
fi

# Define arguments
DB_NAME=$1
NUM_PROCESSES=$2
ORIGIN_VALUE=$3
VERSION_VALUE=$4

# Tables and their columns to update
declare -A TABLES_COLUMNS
TABLES_COLUMNS=(
  ["taxa"]="origin,version"
  ["observers"]="origin,version"
  ["observations"]="origin,version"
  ["photos"]="origin,version"
)

# Function to update columns in parallel
update_columns_in_parallel() {
  local TABLE_NAME=$1
  local COLUMN_NAME=$2
  local VALUE=$3
  local TOTAL_ROWS
  TOTAL_ROWS=$(docker exec ibrida psql -U postgres -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM ${TABLE_NAME};")
  local BATCH_SIZE=$((TOTAL_ROWS / NUM_PROCESSES))

  for ((i=0; i<NUM_PROCESSES; i++)); do
    local OFFSET=$((i * BATCH_SIZE))
    run_update ${TABLE_NAME} ${COLUMN_NAME} ${VALUE} ${OFFSET} ${BATCH_SIZE} ${DB_NAME} &
  done
}

# Update columns in parallel
for TABLE_NAME in "${!TABLES_COLUMNS[@]}"; do
  IFS=',' read -ra COLUMNS <<< "${TABLES_COLUMNS[$TABLE_NAME]}"
  for COLUMN in "${COLUMNS[@]}"; do
    if [ "$COLUMN" == "origin" ]; then
      update_columns_in_parallel "$TABLE_NAME" "$COLUMN" "$ORIGIN_VALUE"
    elif [ "$COLUMN" == "version" ]; then
      update_columns_in_parallel "$TABLE_NAME" "$COLUMN" "$VERSION_VALUE"
    fi
  done
done

# Wait for all processes to finish
wait
echo "All updates completed."


---
Full Path: ingest.sh

#!/bin/bash

# Database and user variables
DB_USER="postgres"
DB_TEMPLATE="template_postgis"
NUM_PROCESSES=16
BASE_DIR="/home/caleb/repo/ibridaDB/dbTools/ingest/v0"

# Source variable
SOURCE="June2024"

# Construct origin value based on source
ORIGIN_VALUE="iNat-${SOURCE}"

# Version variable
VERSION_VALUE="v0"

# Construct database name
DB_NAME="ibrida-${VERSION_VALUE}"

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec ibrida psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Create database, drop if exists
print_progress "Creating database"
docker exec ibrida psql -U "$DB_USER" -c "DROP DATABASE IF EXISTS \"$DB_NAME\";"
docker exec ibrida psql -U "$DB_USER" -c "CREATE DATABASE \"$DB_NAME\" WITH TEMPLATE $DB_TEMPLATE OWNER $DB_USER;"

# Connect to the database and create tables
print_progress "Creating tables"
execute_sql "
BEGIN;

CREATE TABLE observations (
    observation_uuid uuid NOT NULL,
    observer_id integer,
    latitude numeric(15,10),
    longitude numeric(15,10),
    positional_accuracy integer,
    taxon_id integer,
    quality_grade character varying(255),
    observed_on date
);

CREATE TABLE photos (
    photo_uuid uuid NOT NULL,
    photo_id integer NOT NULL,
    observation_uuid uuid NOT NULL,
    observer_id integer,
    extension character varying(5),
    license character varying(255),
    width smallint,
    height smallint,
    position smallint
);

CREATE TABLE taxa (
    taxon_id integer NOT NULL,
    ancestry character varying(255),
    rank_level double precision,
    rank character varying(255),
    name character varying(255),
    active boolean
);

CREATE TABLE observers (
    observer_id integer NOT NULL,
    login character varying(255),
    name character varying(255)
);

COMMIT;
"

# Import data
print_progress "Importing data"
execute_sql "
BEGIN;

COPY observations FROM '/metadata/${SOURCE}/observations.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY photos FROM '/metadata/${SOURCE}/photos.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY taxa FROM '/metadata/${SOURCE}/taxa.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;
COPY observers FROM '/metadata/${SOURCE}/observers.csv' DELIMITER E'\t' QUOTE E'\b' CSV HEADER;

COMMIT;
"

# Create indexes
print_progress "Creating indexes"
execute_sql "
BEGIN;

CREATE INDEX index_photos_photo_uuid ON photos USING btree (photo_uuid);
CREATE INDEX index_photos_observation_uuid ON photos USING btree (observation_uuid);
CREATE INDEX index_photos_position ON photos USING btree (position);
CREATE INDEX index_photos_photo_id ON photos USING btree (photo_id);
CREATE INDEX index_taxa_taxon_id ON taxa USING btree (taxon_id);
CREATE INDEX index_observers_observers_id ON observers USING btree (observer_id);
CREATE INDEX index_observations_observer_id ON observations USING btree (observer_id);
CREATE INDEX index_observations_quality ON observations USING btree (quality_grade);
CREATE INDEX index_observations_taxon_id ON observations USING btree (taxon_id);
CREATE INDEX index_taxa_active ON taxa USING btree (active);
CREATE INDEX index_observations_taxon_id ON observations USING btree (taxon_id);

COMMIT;
"

# Add geom column (parallelized calculation using geom.sh)
print_progress "Adding geom column"
execute_sql "ALTER TABLE observations ADD COLUMN geom public.geometry;"

# Run parallel geom calculations
print_progress "Running parallel geom calculations"
"${BASE_DIR}/geom.sh" "$DB_NAME" "observations" "$NUM_PROCESSES" "$BASE_DIR"

# Create geom index
print_progress "Creating geom index"
execute_sql "
BEGIN;

CREATE INDEX observations_geom ON observations USING GIST (geom);

COMMIT;
"

# Vacuum analyze
print_progress "Vacuum analyze"
execute_sql "VACUUM ANALYZE;"

# Add origin and version columns in parallel
print_progress "Adding origin and version columns"
execute_sql "
BEGIN;

ALTER TABLE taxa ADD COLUMN origin VARCHAR(255);
ALTER TABLE observers ADD COLUMN origin VARCHAR(255);
ALTER TABLE observations ADD COLUMN origin VARCHAR(255);
ALTER TABLE photos ADD COLUMN origin VARCHAR(255);
ALTER TABLE photos ADD COLUMN version VARCHAR(255);
ALTER TABLE observations ADD COLUMN version VARCHAR(255);
ALTER TABLE observers ADD COLUMN version VARCHAR(255);
ALTER TABLE taxa ADD COLUMN version VARCHAR(255);

COMMIT;
"

# Run parallel updates for origin and version columns
print_progress "Running parallel updates for origin and version columns"
"${BASE_DIR}/vers_origin.sh" "$DB_NAME" "$NUM_PROCESSES" "$ORIGIN_VALUE" "$VERSION_VALUE"

# Create indexes for origin and version columns
print_progress "Creating indexes for origin and version columns"
execute_sql "
BEGIN;

CREATE INDEX index_taxa_origins ON taxa USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_taxa_name ON taxa USING GIN (to_tsvector('simple', name));
CREATE INDEX index_observers_origins ON observers USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_observations_origins ON observations USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_photos_origins ON photos USING GIN (to_tsvector('simple', origin));
CREATE INDEX index_photos_version ON photos USING GIN (to_tsvector('simple', version));
CREATE INDEX index_observations_version ON observations USING GIN (to_tsvector('simple', version));
CREATE INDEX index_observers_version ON observers USING GIN (to_tsvector('simple', version));
CREATE INDEX index_taxa_version ON taxa USING GIN (to_tsvector('simple', version));

COMMIT;
"

print_progress "Database setup complete"


---
Full Path: geom.sh

#!/bin/bash

# Function to run the update in parallel
run_update() {
  local OFFSET=$1
  local LIMIT=$2
  local DB_NAME=$3
  local TABLE_NAME=$4

  docker exec ibrida psql -U postgres -d "${DB_NAME}" -c "
  UPDATE ${TABLE_NAME}
  SET geom = ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)::public.geometry
  WHERE observation_uuid IN (
    SELECT observation_uuid
    FROM ${TABLE_NAME}
    ORDER BY observation_uuid
    OFFSET ${OFFSET}
    LIMIT ${LIMIT}
  );"
}

# Check if correct number of arguments are provided
if [ "$#" -ne 4 ]; then
  echo "Usage: $0 <database_name> <table_name> <num_workers> <base_dir>"
  exit 1
fi

# Define arguments
DB_NAME=$1
TABLE_NAME=$2
NUM_PROCESSES=$3
BASE_DIR=$4

# Calculate total rows and batch size
TOTAL_ROWS=$(docker exec ibrida psql -U postgres -d "${DB_NAME}" -t -c "SELECT COUNT(*) FROM ${TABLE_NAME};")
BATCH_SIZE=$((TOTAL_ROWS / NUM_PROCESSES))

# Run updates in parallel
for ((i=0; i<NUM_PROCESSES; i++)); do
  OFFSET=$((i * BATCH_SIZE))
  run_update ${OFFSET} ${BATCH_SIZE} ${DB_NAME} ${TABLE_NAME} &
done

# Wait for all processes to finish
wait
echo "All updates completed."


