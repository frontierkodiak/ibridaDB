Export Configuration:
{
  "repo_root": ".",
  "export_name": "._export.txt",
  "delimiter": "---",
  "dirs_to_traverse": [
    "."
  ],
  "include_top_level_files": "all",
  "included_extensions": "all",
  "subdirs_to_exclude": [
    "__pycache__"
  ],
  "files_to_exclude": [
    "._export.txt"
  ],
  "depth": 10,
  "exhaustive_dir_tree": false,
  "blacklisted_dirs": [
    "__pycache__"
  ],
  "files_to_include": [],
  "output_file": "./._export.txt",
  "exported_files_count": {},
  "total_lines": 0
}
Directory tree, stemming from root ".":
├── ._export.txt
├── cladistic.sh
├── regional_base.sh
└── wrapper.sh

---
Full Path: regional_base.sh

#!/bin/bash

# Use the variables passed from the wrapper script
DB_USER="${DB_USER}"
DB_NAME="${DB_NAME}"
REGION_TAG="${REGION_TAG}"
MIN_OBS="${MIN_OBS}"
DB_CONTAINER="${DB_CONTAINER}"

# Function to set region-specific coordinates
set_region_coordinates() {
  case "$REGION_TAG" in
    "NAfull")
      XMIN=-169.453125
      YMIN=12.211180
      XMAX=-23.554688
      YMAX=84.897147
      ;;
    "EURwest")
      XMIN=-12.128906
      YMIN=40.245992
      XMAX=12.480469
      YMAX=60.586967
      ;;
    "EURnorth")
      XMIN=-25.927734
      YMIN=54.673831
      XMAX=45.966797
      YMAX=71.357067
      ;;
    "EUReast")
      XMIN=10.722656
      YMIN=41.771312
      XMAX=39.550781
      YMAX=59.977005
      ;;
    "EURfull")
      XMIN=-30.761719
      YMIN=33.284620
      XMAX=43.593750
      YMAX=72.262310
      ;;
    "MED")
      XMIN=-16.259766
      YMIN=29.916852
      XMAX=36.474609
      YMAX=46.316584
      ;;
    "AUSfull")
      XMIN=111.269531
      YMIN=-47.989922
      XMAX=181.230469
      YMAX=-9.622414
      ;;
    "ASIAse")
      XMIN=82.441406
      YMIN=-11.523088
      XMAX=153.457031
      YMAX=28.613459
      ;;
    "ASIAeast")
      XMIN=462.304688
      YMIN=23.241346
      XMAX=550.195313
      YMAX=78.630006
      ;;
    "ASIAcentral")
      XMIN=408.515625
      YMIN=36.031332
      XMAX=467.753906
      YMAX=76.142958
      ;;
    "ASIAsouth")
      XMIN=420.468750
      YMIN=1.581830
      XMAX=455.097656
      YMAX=39.232253
      ;;
    "ASIAsw")
      XMIN=386.718750
      YMIN=12.897489
      XMAX=423.281250
      YMAX=48.922499
      ;;
    "ASIA_nw")
      XMIN=393.046875
      YMIN=46.800059
      XMAX=473.203125
      YMAX=81.621352
      ;;
    "SAfull")
      XMIN=271.230469
      YMIN=-57.040730
      XMAX=330.644531
      YMAX=15.114553
      ;;
    "AFRfull")
      XMIN=339.082031
      YMIN=-37.718590
      XMAX=421.699219
      YMAX=39.232253
      ;;
    *)
      echo "Unknown REGION_TAG: $REGION_TAG"
      exit 1
      ;;
  esac
}

# Set region coordinates
set_region_coordinates

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Drop existing tables if they exist
drop_existing_tables() {
  execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa;"
  execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs;"
}

# Drop tables if they exist
drop_existing_tables

# Create table <REGION_TAG>_min<MIN_OBS>_all_taxa
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa"
execute_sql "
BEGIN;

CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa AS
SELECT  
    DISTINCT observations.taxon_id  
FROM  
    observations 
WHERE 
    observations.observation_uuid = ANY (
        SELECT observations.observation_uuid
        FROM observations
        JOIN taxa ON observations.taxon_id = taxa.taxon_id
        WHERE 
            NOT (taxa.rank_level = 10 AND observations.quality_grade != 'research')
            AND observations.latitude BETWEEN ${YMIN} AND ${YMAX}
            AND observations.longitude BETWEEN ${XMIN} AND ${XMAX}
    )
    AND observations.taxon_id IN (
        SELECT observations.taxon_id
        FROM observations
        GROUP BY observations.taxon_id
        HAVING COUNT(observation_uuid) >= ${MIN_OBS}
    );

COMMIT;
"

# Create table <REGION_TAG>_min<MIN_OBS>_all_taxa_obs (NO VERSION, ORIGIN)
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs"
execute_sql "
BEGIN;

CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs AS
SELECT  
    observation_uuid, observer_id, latitude, longitude, positional_accuracy, taxon_id, quality_grade,  
    observed_on
FROM
    observations
WHERE
    taxon_id IN (
        SELECT taxon_id
        FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa
    );

COMMIT;
"

print_progress "Regional base tables created"

# NOTE: Below is the original query that included version and origin.
# # Create table <REGION_TAG>_min<MIN_OBS>_all_taxa_obs
# print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs"
# execute_sql "
# BEGIN;

# CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs AS
# SELECT  
#     observation_uuid, observer_id, latitude, longitude, positional_accuracy, taxon_id, quality_grade,  
#     observed_on, origin, version
# FROM
#     observations
# WHERE
#     taxon_id IN (
#         SELECT taxon_id
#         FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa
#     );

# COMMIT;
# "

# print_progress "Regional base tables created"


---
Full Path: cladistic.sh

#!/bin/bash
## dbTools/export/v0/cladistic.sh

# Use the variables passed from the wrapper script
DB_USER="${DB_USER}"
DB_NAME="${DB_NAME}"
REGION_TAG="${REGION_TAG}"
MIN_OBS="${MIN_OBS}"
MAX_RN="${MAX_RN}"
PRIMARY_ONLY="${PRIMARY_ONLY}"
EXPORT_SUBDIR="${EXPORT_SUBDIR}"
DB_CONTAINER="${DB_CONTAINER}"

# Clades and their respective ancestry filters
declare -A CLADES
CLADES=( 
    ["arthropoda"]="48460/1/47120/%"
    ["aves"]="48460/1/2/355675/3/%"
    ["reptilia"]="48460/1/2/355675/26036/%"
    ["mammalia"]="48460/1/2/355675/40151%"
    ["amphibia"]="48460/1/2/355675/20978%"
    ["angiospermae"]="48460/47126/211194/47125/%"
)

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Ensure export directory exists and is writable
EXPORT_DIR="/exports/${EXPORT_SUBDIR}"
if [ ! -d "$EXPORT_DIR" ]; then
  mkdir -p "$EXPORT_DIR"
fi

if [ ! -w "$EXPORT_DIR" ]; then
  echo "Error: Directory $EXPORT_DIR is not writable."
  exit 1
fi

# Function to process a clade
process_clade() {
  local clade=$1
  local ancestry_filter=${CLADES[$clade]}
  local table_name="${REGION_TAG}_${clade}_min${MIN_OBS}all_cap${MAX_RN}"
  local photos_table_name="${table_name}_photos"
  local export_path="${EXPORT_DIR}/${photos_table_name}.csv"

  if [ -z "$ancestry_filter" ]; then
    echo "Unknown clade: $clade"
    exit 1
  fi

  # Drop existing tables
  execute_sql "DROP TABLE IF EXISTS ${table_name};"
  execute_sql "DROP TABLE IF EXISTS ${photos_table_name};"

  # Create table for the clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${table_name}"
  execute_sql "
  CREATE TABLE ${table_name} AS (
      SELECT  
          observation_uuid, 
          observer_id, 
          latitude, 
          longitude, 
          positional_accuracy, 
          taxon_id, 
          quality_grade,  
          observed_on,
          ROW_NUMBER() OVER (
              PARTITION BY taxon_id 
              ORDER BY RANDOM()
          ) as rn
      FROM
          ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
      WHERE
          taxon_id IN (
              SELECT taxon_id
              FROM taxa
              WHERE ancestry LIKE '${ancestry_filter}'
          )
          AND taxon_id IN (
              SELECT taxon_id
              FROM ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
              GROUP BY taxon_id
              HAVING COUNT(*) >= ${MIN_OBS}
          )
  );
  DELETE FROM ${table_name} WHERE rn > ${MAX_RN};
  "

  # Create photos table for the clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${photos_table_name}"
  local photos_where_clause=""
  if [ "$PRIMARY_ONLY" = true ]; then
    photos_where_clause="AND t2.position = 0"
  fi
  execute_sql "
  CREATE TABLE ${photos_table_name} AS
  SELECT  
      t1.observation_uuid, t1.latitude, t1.longitude, t1.positional_accuracy, t1.taxon_id,  
      t1.observed_on, t2.photo_uuid, t2.photo_id, t2.extension, t2.width, t2.height, t2.position
  FROM
      ${table_name} t1
      JOIN photos t2
      ON t1.observation_uuid = t2.observation_uuid
  WHERE 1=1 ${photos_where_clause};
  ALTER TABLE ${photos_table_name} ADD COLUMN ancestry varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank_level double precision;  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN name varchar(255);  
  UPDATE ${photos_table_name} t1  
  SET ancestry = t2.ancestry  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank_level = t2.rank_level  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank = t2.rank  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET name = t2.name  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;
  VACUUM ANALYZE ${photos_table_name};
  "

  # Export photos table to CSV
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Exporting table ${photos_table_name} to CSV"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "\copy (SELECT observation_uuid, latitude, longitude, positional_accuracy, taxon_id, observed_on, photo_uuid, photo_id, extension, width, height, position, ancestry, rank_level, rank, name FROM ${photos_table_name}) TO '${export_path}' DELIMITER ',' CSV HEADER;"
}

# Function to process the "other" clade
process_other_clade() {
  local clade="other"
  local table_name="${REGION_TAG}_${clade}_min${MIN_OBS}all_cap${MAX_RN}"
  local photos_table_name="${table_name}_photos"
  local export_path="${EXPORT_DIR}/${photos_table_name}.csv"

  # Construct the exclusion filter for predefined clades
  local exclusion_filters=""
  for ancestry_filter in "${CLADES[@]}"; do
    exclusion_filters+="AND ancestry NOT LIKE '${ancestry_filter}' "
  done

  # Drop existing tables
  execute_sql "DROP TABLE IF EXISTS ${table_name};"
  execute_sql "DROP TABLE IF EXISTS ${photos_table_name};"

  # Create table for the "other" clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${table_name}"
  execute_sql "
  CREATE TABLE ${table_name} AS (
      SELECT  
          observation_uuid, 
          observer_id, 
          latitude, 
          longitude, 
          positional_accuracy, 
          taxon_id, 
          quality_grade,  
          observed_on,
          ROW_NUMBER() OVER (
              PARTITION BY taxon_id 
              ORDER BY RANDOM()
          ) as rn
      FROM
          ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
      WHERE
          taxon_id IN (
              SELECT taxon_id
              FROM taxa
              WHERE 1=1 ${exclusion_filters}
          )
          AND taxon_id IN (
              SELECT taxon_id
              FROM ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
              GROUP BY taxon_id
              HAVING COUNT(*) >= ${MIN_OBS}
          )
  );
  DELETE FROM ${table_name} WHERE rn > ${MAX_RN};
  "

  # Create photos table for the "other" clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${photos_table_name}"
  local photos_where_clause=""
  if [ "$PRIMARY_ONLY" = true ]; then
    photos_where_clause="AND t2.position = 0"
  fi
  execute_sql "
  CREATE TABLE ${photos_table_name} AS
  SELECT  
      t1.observation_uuid, t1.latitude, t1.longitude, t1.positional_accuracy, t1.taxon_id,  
      t1.observed_on, t2.photo_uuid, t2.photo_id, t2.extension, t2.width, t2.height, t2.position
  FROM
      ${table_name} t1
      JOIN photos t2
      ON t1.observation_uuid = t2.observation_uuid
  WHERE 1=1 ${photos_where_clause};
  ALTER TABLE ${photos_table_name} ADD COLUMN ancestry varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank_level double precision;  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN name varchar(255);  
  UPDATE ${photos_table_name} t1  
  SET ancestry = t2.ancestry  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank_level = t2.rank_level  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank = t2.rank  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET name = t2.name  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;
  VACUUM ANALYZE ${photos_table_name};
  "

  # Export photos table to CSV
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Exporting table ${photos_table_name} to CSV"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "\copy (SELECT observation_uuid, latitude, longitude, positional_accuracy, taxon_id, observed_on, photo_uuid, photo_id, extension, width, height, position, ancestry, rank_level, rank, name FROM ${photos_table_name}) TO '${export_path}' DELIMITER ',' CSV HEADER;"
}

# Process each clade
for clade in "${!CLADES[@]}"; do
  process_clade "$clade"
done

# Process the "other" clade
process_other_clade

print_progress "All clades processed and exported"


---
Full Path: wrapper.sh

#!/bin/bash

# Define variables
DB_USER="postgres"
VERSION_VALUE="v0"
DB_NAME="ibrida-${VERSION_VALUE}"
REGION_TAG="NAfull"
MIN_OBS=50
MAX_RN=4000
PRIMARY_ONLY=true  # Set this to true to select only primary photos (position == 0)
EXPORT_SUBDIR="iNat-June2024/${VERSION_VALUE}/primary_only"  # Subdirectory for CSV exports
DB_CONTAINER="fast-ibrida-1"  # Update this to your container name

# Paths to the scripts
REGIONAL_BASE_SCRIPT="/home/caleb/repo/ibridaDB/dbTools/export/v0/regional_base.sh"
CLADISTIC_SCRIPT="/home/caleb/repo/ibridaDB/dbTools/export/v0/cladistic.sh"

# Function to execute a script and check its success
execute_script() {
  local script="$1"
  if ! bash "$script"; then
    echo "Error: Script $script failed."
    exit 1
  fi
}

# Export variables to be used by the child scripts
export DB_USER VERSION_VALUE DB_NAME REGION_TAG MIN_OBS MAX_RN PRIMARY_ONLY EXPORT_SUBDIR DB_CONTAINER

# # Execute the regional_base.sh script
# NOTE: Commented as we already ran this successfully.
# execute_script "$REGIONAL_BASE_SCRIPT"

# If the first script succeeds, execute the cladistic.sh script
execute_script "$CLADISTIC_SCRIPT"

echo "All scripts executed successfully."

# NOTE: Version and origin temporarily removed from export tables.
# NOTE: Version still used for export path.


---
Full Path: regional_base.sh

#!/bin/bash

# Use the variables passed from the wrapper script
DB_USER="${DB_USER}"
DB_NAME="${DB_NAME}"
REGION_TAG="${REGION_TAG}"
MIN_OBS="${MIN_OBS}"
DB_CONTAINER="${DB_CONTAINER}"

# Function to set region-specific coordinates
set_region_coordinates() {
  case "$REGION_TAG" in
    "NAfull")
      XMIN=-169.453125
      YMIN=12.211180
      XMAX=-23.554688
      YMAX=84.897147
      ;;
    "EURwest")
      XMIN=-12.128906
      YMIN=40.245992
      XMAX=12.480469
      YMAX=60.586967
      ;;
    "EURnorth")
      XMIN=-25.927734
      YMIN=54.673831
      XMAX=45.966797
      YMAX=71.357067
      ;;
    "EUReast")
      XMIN=10.722656
      YMIN=41.771312
      XMAX=39.550781
      YMAX=59.977005
      ;;
    "EURfull")
      XMIN=-30.761719
      YMIN=33.284620
      XMAX=43.593750
      YMAX=72.262310
      ;;
    "MED")
      XMIN=-16.259766
      YMIN=29.916852
      XMAX=36.474609
      YMAX=46.316584
      ;;
    "AUSfull")
      XMIN=111.269531
      YMIN=-47.989922
      XMAX=181.230469
      YMAX=-9.622414
      ;;
    "ASIAse")
      XMIN=82.441406
      YMIN=-11.523088
      XMAX=153.457031
      YMAX=28.613459
      ;;
    "ASIAeast")
      XMIN=462.304688
      YMIN=23.241346
      XMAX=550.195313
      YMAX=78.630006
      ;;
    "ASIAcentral")
      XMIN=408.515625
      YMIN=36.031332
      XMAX=467.753906
      YMAX=76.142958
      ;;
    "ASIAsouth")
      XMIN=420.468750
      YMIN=1.581830
      XMAX=455.097656
      YMAX=39.232253
      ;;
    "ASIAsw")
      XMIN=386.718750
      YMIN=12.897489
      XMAX=423.281250
      YMAX=48.922499
      ;;
    "ASIA_nw")
      XMIN=393.046875
      YMIN=46.800059
      XMAX=473.203125
      YMAX=81.621352
      ;;
    "SAfull")
      XMIN=271.230469
      YMIN=-57.040730
      XMAX=330.644531
      YMAX=15.114553
      ;;
    "AFRfull")
      XMIN=339.082031
      YMIN=-37.718590
      XMAX=421.699219
      YMAX=39.232253
      ;;
    *)
      echo "Unknown REGION_TAG: $REGION_TAG"
      exit 1
      ;;
  esac
}

# Set region coordinates
set_region_coordinates

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Drop existing tables if they exist
drop_existing_tables() {
  execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa;"
  execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs;"
}

# Drop tables if they exist
drop_existing_tables

# Create table <REGION_TAG>_min<MIN_OBS>_all_taxa
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa"
execute_sql "
BEGIN;

CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa AS
SELECT  
    DISTINCT observations.taxon_id  
FROM  
    observations 
WHERE 
    observations.observation_uuid = ANY (
        SELECT observations.observation_uuid
        FROM observations
        JOIN taxa ON observations.taxon_id = taxa.taxon_id
        WHERE 
            NOT (taxa.rank_level = 10 AND observations.quality_grade != 'research')
            AND observations.latitude BETWEEN ${YMIN} AND ${YMAX}
            AND observations.longitude BETWEEN ${XMIN} AND ${XMAX}
    )
    AND observations.taxon_id IN (
        SELECT observations.taxon_id
        FROM observations
        GROUP BY observations.taxon_id
        HAVING COUNT(observation_uuid) >= ${MIN_OBS}
    );

COMMIT;
"

# Create table <REGION_TAG>_min<MIN_OBS>_all_taxa_obs (NO VERSION, ORIGIN)
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs"
execute_sql "
BEGIN;

CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs AS
SELECT  
    observation_uuid, observer_id, latitude, longitude, positional_accuracy, taxon_id, quality_grade,  
    observed_on
FROM
    observations
WHERE
    taxon_id IN (
        SELECT taxon_id
        FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa
    );

COMMIT;
"

print_progress "Regional base tables created"

# NOTE: Below is the original query that included version and origin.
# # Create table <REGION_TAG>_min<MIN_OBS>_all_taxa_obs
# print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs"
# execute_sql "
# BEGIN;

# CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs AS
# SELECT  
#     observation_uuid, observer_id, latitude, longitude, positional_accuracy, taxon_id, quality_grade,  
#     observed_on, origin, version
# FROM
#     observations
# WHERE
#     taxon_id IN (
#         SELECT taxon_id
#         FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa
#     );

# COMMIT;
# "

# print_progress "Regional base tables created"


---
Full Path: cladistic.sh

#!/bin/bash
## dbTools/export/v0/cladistic.sh

# Use the variables passed from the wrapper script
DB_USER="${DB_USER}"
DB_NAME="${DB_NAME}"
REGION_TAG="${REGION_TAG}"
MIN_OBS="${MIN_OBS}"
MAX_RN="${MAX_RN}"
PRIMARY_ONLY="${PRIMARY_ONLY}"
EXPORT_SUBDIR="${EXPORT_SUBDIR}"
DB_CONTAINER="${DB_CONTAINER}"

# Clades and their respective ancestry filters
declare -A CLADES
CLADES=( 
    ["arthropoda"]="48460/1/47120/%"
    ["aves"]="48460/1/2/355675/3/%"
    ["reptilia"]="48460/1/2/355675/26036/%"
    ["mammalia"]="48460/1/2/355675/40151%"
    ["amphibia"]="48460/1/2/355675/20978%"
    ["angiospermae"]="48460/47126/211194/47125/%"
)

# Function to execute SQL commands
execute_sql() {
  local sql="$1"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "$sql"
}

# Function to print progress
print_progress() {
  local message="$1"
  echo "======================================"
  echo "$message"
  echo "======================================"
}

# Ensure export directory exists and is writable
EXPORT_DIR="/exports/${EXPORT_SUBDIR}"
if [ ! -d "$EXPORT_DIR" ]; then
  mkdir -p "$EXPORT_DIR"
fi

if [ ! -w "$EXPORT_DIR" ]; then
  echo "Error: Directory $EXPORT_DIR is not writable."
  exit 1
fi

# Function to process a clade
process_clade() {
  local clade=$1
  local ancestry_filter=${CLADES[$clade]}
  local table_name="${REGION_TAG}_${clade}_min${MIN_OBS}all_cap${MAX_RN}"
  local photos_table_name="${table_name}_photos"
  local export_path="${EXPORT_DIR}/${photos_table_name}.csv"

  if [ -z "$ancestry_filter" ]; then
    echo "Unknown clade: $clade"
    exit 1
  fi

  # Drop existing tables
  execute_sql "DROP TABLE IF EXISTS ${table_name};"
  execute_sql "DROP TABLE IF EXISTS ${photos_table_name};"

  # Create table for the clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${table_name}"
  execute_sql "
  CREATE TABLE ${table_name} AS (
      SELECT  
          observation_uuid, 
          observer_id, 
          latitude, 
          longitude, 
          positional_accuracy, 
          taxon_id, 
          quality_grade,  
          observed_on,
          ROW_NUMBER() OVER (
              PARTITION BY taxon_id 
              ORDER BY RANDOM()
          ) as rn
      FROM
          ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
      WHERE
          taxon_id IN (
              SELECT taxon_id
              FROM taxa
              WHERE ancestry LIKE '${ancestry_filter}'
          )
          AND taxon_id IN (
              SELECT taxon_id
              FROM ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
              GROUP BY taxon_id
              HAVING COUNT(*) >= ${MIN_OBS}
          )
  );
  DELETE FROM ${table_name} WHERE rn > ${MAX_RN};
  "

  # Create photos table for the clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${photos_table_name}"
  local photos_where_clause=""
  if [ "$PRIMARY_ONLY" = true ]; then
    photos_where_clause="AND t2.position = 0"
  fi
  execute_sql "
  CREATE TABLE ${photos_table_name} AS
  SELECT  
      t1.observation_uuid, t1.latitude, t1.longitude, t1.positional_accuracy, t1.taxon_id,  
      t1.observed_on, t2.photo_uuid, t2.photo_id, t2.extension, t2.width, t2.height, t2.position
  FROM
      ${table_name} t1
      JOIN photos t2
      ON t1.observation_uuid = t2.observation_uuid
  WHERE 1=1 ${photos_where_clause};
  ALTER TABLE ${photos_table_name} ADD COLUMN ancestry varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank_level double precision;  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN name varchar(255);  
  UPDATE ${photos_table_name} t1  
  SET ancestry = t2.ancestry  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank_level = t2.rank_level  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank = t2.rank  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET name = t2.name  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;
  VACUUM ANALYZE ${photos_table_name};
  "

  # Export photos table to CSV
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Exporting table ${photos_table_name} to CSV"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "\copy (SELECT observation_uuid, latitude, longitude, positional_accuracy, taxon_id, observed_on, photo_uuid, photo_id, extension, width, height, position, ancestry, rank_level, rank, name FROM ${photos_table_name}) TO '${export_path}' DELIMITER ',' CSV HEADER;"
}

# Function to process the "other" clade
process_other_clade() {
  local clade="other"
  local table_name="${REGION_TAG}_${clade}_min${MIN_OBS}all_cap${MAX_RN}"
  local photos_table_name="${table_name}_photos"
  local export_path="${EXPORT_DIR}/${photos_table_name}.csv"

  # Construct the exclusion filter for predefined clades
  local exclusion_filters=""
  for ancestry_filter in "${CLADES[@]}"; do
    exclusion_filters+="AND ancestry NOT LIKE '${ancestry_filter}' "
  done

  # Drop existing tables
  execute_sql "DROP TABLE IF EXISTS ${table_name};"
  execute_sql "DROP TABLE IF EXISTS ${photos_table_name};"

  # Create table for the "other" clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${table_name}"
  execute_sql "
  CREATE TABLE ${table_name} AS (
      SELECT  
          observation_uuid, 
          observer_id, 
          latitude, 
          longitude, 
          positional_accuracy, 
          taxon_id, 
          quality_grade,  
          observed_on,
          ROW_NUMBER() OVER (
              PARTITION BY taxon_id 
              ORDER BY RANDOM()
          ) as rn
      FROM
          ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
      WHERE
          taxon_id IN (
              SELECT taxon_id
              FROM taxa
              WHERE 1=1 ${exclusion_filters}
          )
          AND taxon_id IN (
              SELECT taxon_id
              FROM ${REGION_TAG}_min${MIN_OBS}all_taxa_obs
              GROUP BY taxon_id
              HAVING COUNT(*) >= ${MIN_OBS}
          )
  );
  DELETE FROM ${table_name} WHERE rn > ${MAX_RN};
  "

  # Create photos table for the "other" clade
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Creating table ${photos_table_name}"
  local photos_where_clause=""
  if [ "$PRIMARY_ONLY" = true ]; then
    photos_where_clause="AND t2.position = 0"
  fi
  execute_sql "
  CREATE TABLE ${photos_table_name} AS
  SELECT  
      t1.observation_uuid, t1.latitude, t1.longitude, t1.positional_accuracy, t1.taxon_id,  
      t1.observed_on, t2.photo_uuid, t2.photo_id, t2.extension, t2.width, t2.height, t2.position
  FROM
      ${table_name} t1
      JOIN photos t2
      ON t1.observation_uuid = t2.observation_uuid
  WHERE 1=1 ${photos_where_clause};
  ALTER TABLE ${photos_table_name} ADD COLUMN ancestry varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank_level double precision;  
  ALTER TABLE ${photos_table_name} ADD COLUMN rank varchar(255);  
  ALTER TABLE ${photos_table_name} ADD COLUMN name varchar(255);  
  UPDATE ${photos_table_name} t1  
  SET ancestry = t2.ancestry  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank_level = t2.rank_level  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET rank = t2.rank  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;  
  UPDATE ${photos_table_name} t1  
  SET name = t2.name  
  FROM taxa t2  
  WHERE t1.taxon_id = t2.taxon_id;
  VACUUM ANALYZE ${photos_table_name};
  "

  # Export photos table to CSV
  ## NOTE: Origin temporarily removed from export tables.
  print_progress "Exporting table ${photos_table_name} to CSV"
  docker exec "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" -c "\copy (SELECT observation_uuid, latitude, longitude, positional_accuracy, taxon_id, observed_on, photo_uuid, photo_id, extension, width, height, position, ancestry, rank_level, rank, name FROM ${photos_table_name}) TO '${export_path}' DELIMITER ',' CSV HEADER;"
}

# Process each clade
for clade in "${!CLADES[@]}"; do
  process_clade "$clade"
done

# Process the "other" clade
process_other_clade

print_progress "All clades processed and exported"


---
Full Path: wrapper.sh

#!/bin/bash

# Define variables
DB_USER="postgres"
VERSION_VALUE="v0"
DB_NAME="ibrida-${VERSION_VALUE}"
REGION_TAG="NAfull"
MIN_OBS=50
MAX_RN=4000
PRIMARY_ONLY=true  # Set this to true to select only primary photos (position == 0)
EXPORT_SUBDIR="iNat-June2024/${VERSION_VALUE}/primary_only"  # Subdirectory for CSV exports
DB_CONTAINER="fast-ibrida-1"  # Update this to your container name

# Paths to the scripts
REGIONAL_BASE_SCRIPT="/home/caleb/repo/ibridaDB/dbTools/export/v0/regional_base.sh"
CLADISTIC_SCRIPT="/home/caleb/repo/ibridaDB/dbTools/export/v0/cladistic.sh"

# Function to execute a script and check its success
execute_script() {
  local script="$1"
  if ! bash "$script"; then
    echo "Error: Script $script failed."
    exit 1
  fi
}

# Export variables to be used by the child scripts
export DB_USER VERSION_VALUE DB_NAME REGION_TAG MIN_OBS MAX_RN PRIMARY_ONLY EXPORT_SUBDIR DB_CONTAINER

# # Execute the regional_base.sh script
# NOTE: Commented as we already ran this successfully.
# execute_script "$REGIONAL_BASE_SCRIPT"

# If the first script succeeds, execute the cladistic.sh script
execute_script "$CLADISTIC_SCRIPT"

echo "All scripts executed successfully."

# NOTE: Version and origin temporarily removed from export tables.
# NOTE: Version still used for export path.


