Directory tree, stemming from root "/home/caleb/repo/ibridaDB/dbTools/export/v0":
├── common (439 lines)
│   ├── cladistic.sh (126)
│   ├── functions.sh (52)
│   ├── main.sh (62)
│   └── regional_base.sh (199)
└── r1 (58)
    │   └── wrapper.sh (58)
----
----
Full Path: common/main.sh

#!/bin/bash

# Source common functions
source "${BASE_DIR}/common/functions.sh"

# Validate required variables
required_vars=(
    "DB_USER" "VERSION_VALUE" "RELEASE_VALUE" "ORIGIN_VALUE" 
    "DB_NAME" "REGION_TAG" "MIN_OBS" "MAX_RN" 
    "DB_CONTAINER" "HOST_EXPORT_BASE_PATH" "CONTAINER_EXPORT_BASE_PATH"
    "EXPORT_GROUP"
)

for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "Error: Required variable $var is not set"
        exit 1
    fi
done

# Create export directory structure
print_progress "Creating export directory structure"
EXPORT_DIR="${CONTAINER_EXPORT_BASE_PATH}/${EXPORT_SUBDIR}"
HOST_EXPORT_DIR="${HOST_EXPORT_BASE_PATH}/${EXPORT_SUBDIR}"

# Create host directory with proper permissions
ensure_directory "${HOST_EXPORT_DIR}"

# Create PostgreSQL extension and role if needed
execute_sql "
DO \$\$
BEGIN
    CREATE EXTENSION IF NOT EXISTS dblink;
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'exportuser') THEN
        CREATE ROLE exportuser;
    END IF;
END \$\$;"

# Run regional base creation (source functions first)
print_progress "Creating regional base tables"
source "${BASE_DIR}/common/regional_base.sh"
send_notification "${REGION_TAG} regional base tables created"

# Run cladistic filtering
print_progress "Applying cladistic filters"
source "${BASE_DIR}/common/cladistic.sh"
send_notification "${EXPORT_GROUP} cladistic filtering complete"

# Export summary
print_progress "Creating export summary"
cat > "${HOST_EXPORT_DIR}/export_summary.txt" << EOL
Export Summary
Version: ${VERSION_VALUE}
Release: ${RELEASE_VALUE}
Region: ${REGION_TAG}
Minimum Observations: ${MIN_OBS}
Maximum Random Number: ${MAX_RN}
Export Group: ${EXPORT_GROUP}
Date: $(date)
EOL

print_progress "Export process complete"

----
Full Path: common/regional_base.sh

#!/bin/bash

# Note: functions are sourced from main.sh

# Function to set region-specific coordinates
set_region_coordinates() {
  case "$REGION_TAG" in
    "NAfull")
      XMIN=-169.453125
      YMIN=12.211180
      XMAX=-23.554688
      YMAX=84.897147
      ;;
    "EURwest")
      XMIN=-12.128906
      YMIN=40.245992
      XMAX=12.480469
      YMAX=60.586967
      ;;
    "EURnorth")
      XMIN=-25.927734
      YMIN=54.673831
      XMAX=45.966797
      YMAX=71.357067
      ;;
    "EUReast")
      XMIN=10.722656
      YMIN=41.771312
      XMAX=39.550781
      YMAX=59.977005
      ;;
    "EURfull")
      XMIN=-30.761719
      YMIN=33.284620
      XMAX=43.593750
      YMAX=72.262310
      ;;
    "MED")
      XMIN=-16.259766
      YMIN=29.916852
      XMAX=36.474609
      YMAX=46.316584
      ;;
    "AUSfull")
      XMIN=111.269531
      YMIN=-47.989922
      XMAX=181.230469
      YMAX=-9.622414
      ;;
    "ASIAse")
      XMIN=82.441406
      YMIN=-11.523088
      XMAX=153.457031
      YMAX=28.613459
      ;;
    "ASIAeast")
      XMIN=462.304688
      YMIN=23.241346
      XMAX=550.195313
      YMAX=78.630006
      ;;
    "ASIAcentral")
      XMIN=408.515625
      YMIN=36.031332
      XMAX=467.753906
      YMAX=76.142958
      ;;
    "ASIAsouth")
      XMIN=420.468750
      YMIN=1.581830
      XMAX=455.097656
      YMAX=39.232253
      ;;
    "ASIAsw")
      XMIN=386.718750
      YMIN=12.897489
      XMAX=423.281250
      YMAX=48.922499
      ;;
    "ASIA_nw")
      XMIN=393.046875
      YMIN=46.800059
      XMAX=473.203125
      YMAX=81.621352
      ;;
    "SAfull")
      XMIN=271.230469
      YMIN=-57.040730
      XMAX=330.644531
      YMAX=15.114553
      ;;
    "AFRfull")
      XMIN=339.082031
      YMIN=-37.718590
      XMAX=421.699219
      YMAX=39.232253
      ;;
    *)
      echo "Unknown REGION_TAG: $REGION_TAG"
      exit 1
      ;;
  esac
}


# Set region coordinates
set_region_coordinates

# # Debug: Check version and release values
# print_progress "Debugging database parameters"
# execute_sql "
# SELECT DISTINCT version, release, count(*)
# FROM observations
# GROUP BY version, release;"

# # Debug: Check coordinate bounds
# print_progress "Checking observations within coordinate bounds"
# execute_sql "
# SELECT COUNT(*)
# FROM observations
# WHERE latitude BETWEEN ${YMIN} AND ${YMAX}
# AND longitude BETWEEN ${XMIN} AND ${XMAX};"

# # Debug: Check quality grade distribution
# print_progress "Checking quality grade distribution"
# execute_sql "
# SELECT quality_grade, COUNT(*)
# FROM observations
# WHERE version = '${VERSION_VALUE}'
# AND release = '${RELEASE_VALUE}'
# GROUP BY quality_grade;"

# Drop existing tables if they exist
print_progress "Dropping existing tables"
execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa CASCADE;"
execute_sql "DROP TABLE IF EXISTS ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs CASCADE;"

# Create table with debug output
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa with debug"
execute_sql "
CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa AS
WITH debug_counts AS (
    SELECT COUNT(*) as total_obs,
           COUNT(DISTINCT taxon_id) as unique_taxa
    FROM observations
    WHERE
    -- TEMPORARY HOTFIX: Commenting out version filters until bulk update is complete
    -- version = '${VERSION_VALUE}'
    -- AND release = '${RELEASE_VALUE}'
    -- AND 
    geom && ST_MakeEnvelope(${XMIN}, ${YMIN}, ${XMAX}, ${YMAX}, 4326)
)
SELECT * FROM debug_counts;

SELECT DISTINCT observations.taxon_id
FROM observations
JOIN taxa ON observations.taxon_id = taxa.taxon_id
WHERE 
    -- TEMPORARY HOTFIX: Commenting out version filters until bulk update is complete
    -- observations.version = '${VERSION_VALUE}'
    -- AND observations.release = '${RELEASE_VALUE}'
    -- AND 
    NOT (taxa.rank_level = 10 AND observations.quality_grade != 'research')
    AND geom && ST_MakeEnvelope(${XMIN}, ${YMIN}, ${XMAX}, ${YMAX}, 4326)
    AND observations.taxon_id IN (
        SELECT observations.taxon_id
        FROM observations
        WHERE 
        -- TEMPORARY HOTFIX: Commenting out version filters until bulk update is complete
        -- version = '${VERSION_VALUE}'
        -- AND release = '${RELEASE_VALUE}'
        -- AND 
        1=1
        GROUP BY observations.taxon_id
        HAVING COUNT(observation_uuid) >= ${MIN_OBS}
    );

# Create table <REGION_TAG>_min<MIN_OBS>_all_taxa_obs with dynamic columns
print_progress "Creating table ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs"
OBS_COLUMNS=$(get_obs_columns)

# Debug: show the columns being used
echo "Using columns: ${OBS_COLUMNS}"

execute_sql "
CREATE TABLE ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs AS
SELECT ${OBS_COLUMNS}
FROM observations
WHERE 
    -- TEMPORARY HOTFIX: Commenting out version filters until bulk update is complete
    -- version = '${VERSION_VALUE}'
    -- AND release = '${RELEASE_VALUE}'
    -- AND 
    taxon_id IN (
        SELECT taxon_id
        FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa
    );"

print_progress "Regional base tables created"

----
Full Path: common/functions.sh

#!/bin/bash

# Common functions used across export scripts

# Function to execute SQL commands
execute_sql() {
    local sql="$1"
    docker exec ${DB_CONTAINER} psql -U ${DB_USER} -d "${DB_NAME}" -c "$sql"
}

# Function to print progress
print_progress() {
    echo "======================================"
    echo "$1"
    echo "======================================"
}

get_obs_columns() {
    # Start with standard columns
    local cols="observation_uuid, observer_id, latitude, longitude, positional_accuracy, taxon_id, quality_grade, observed_on"
    
    # TEMPORARY HOTFIX: Commenting out version tracking columns until bulk update is complete
    # Add version tracking columns
    # cols="${cols}, origin, version, release"
    
    # Check if anomaly_score exists in this release
    if [[ "${RELEASE_VALUE}" == "r1" ]]; then
        cols="${cols}, anomaly_score"
    fi
    
    echo "$cols"
}

# Function to ensure directory exists with proper permissions
ensure_directory() {
    local dir="$1"
    mkdir -p "${dir}"
    chmod -R 777 "${dir}"
}

# Function to send ntfy notification
send_notification() {
    local message="$1"
    curl -d "$message" polliserve:8089/ibridaDB
}

# Export the functions
export -f execute_sql
export -f print_progress
export -f get_obs_columns
export -f ensure_directory
export -f send_notification

----
Full Path: common/cladistic.sh

#!/bin/bash

# Note: functions.sh is already sourced from main.sh

# Function to get taxa IDs for a given metaclade
get_metaclade_taxa() {
    local metaclade=$1
    case $metaclade in
        "primary_terrestrial_arthropoda")
            # Include Insecta and Arachnida, exclude aquatic groups
            execute_sql "
                WITH RECURSIVE taxonomy AS (
                    SELECT taxon_id, ancestry, rank, name, active
                    FROM taxa
                    WHERE name IN ('Insecta', 'Arachnida')
                    UNION ALL
                    SELECT t.taxon_id, t.ancestry, t.rank, t.name, t.active
                    FROM taxa t
                    INNER JOIN taxonomy tax ON t.ancestry LIKE tax.ancestry || '/%'
                        OR t.ancestry = tax.ancestry
                    WHERE t.active = true
                )
                SELECT DISTINCT taxon_id 
                FROM taxonomy
                WHERE active = true
                AND taxon_id NOT IN (
                    SELECT DISTINCT t.taxon_id
                    FROM taxa t
                    WHERE t.name IN ('Ephemeroptera', 'Plecoptera', 'Trichoptera', 'Odonata')
                    OR t.ancestry LIKE '%/48549%'  -- Exclude aquatic insects
                );"
            ;;
        "amphibia")
            execute_sql "
                WITH RECURSIVE taxonomy AS (
                    SELECT taxon_id, ancestry, rank, name, active
                    FROM taxa
                    WHERE name = 'Amphibia'
                    UNION ALL
                    SELECT t.taxon_id, t.ancestry, t.rank, t.name, t.active
                    FROM taxa t
                    INNER JOIN taxonomy tax ON t.ancestry LIKE tax.ancestry || '/%'
                        OR t.ancestry = tax.ancestry
                    WHERE t.active = true
                )
                SELECT DISTINCT taxon_id 
                FROM taxonomy
                WHERE active = true;"
            ;;
        *)
            echo "Unknown metaclade: $metaclade"
            exit 1
            ;;
    esac
}

# Create filtered tables based on metaclade
print_progress "Creating filtered tables for ${EXPORT_GROUP}"
execute_sql "
CREATE TEMPORARY TABLE metaclade_taxa AS
$(get_metaclade_taxa ${EXPORT_GROUP});

CREATE TABLE ${EXPORT_GROUP}_observations AS
SELECT ${OBS_COLUMNS}
FROM ${REGION_TAG}_min${MIN_OBS}_all_taxa_obs obs
WHERE obs.taxon_id IN (SELECT taxon_id FROM metaclade_taxa);"

# Export filtered observations
print_progress "Exporting filtered observations"
if [ "$PRIMARY_ONLY" = true ]; then
    execute_sql "\COPY (
        SELECT o.*, 
               p.photo_uuid,
               p.photo_id,
               p.extension,
               p.license,
               p.width,
               p.height,
               p.position
        FROM ${EXPORT_GROUP}_observations o
        JOIN photos p ON o.observation_uuid = p.observation_uuid
        WHERE p.position = 0
        AND o.quality_grade = 'research'
        ORDER BY random()
        LIMIT ${MAX_RN}
    ) TO '${EXPORT_DIR}/${EXPORT_GROUP}_photos.csv' WITH CSV HEADER DELIMITER E'\t';"
else
    execute_sql "\COPY (
        SELECT o.*, 
               p.photo_uuid,
               p.photo_id,
               p.extension,
               p.license,
               p.width,
               p.height,
               p.position
        FROM ${EXPORT_GROUP}_observations o
        JOIN photos p ON o.observation_uuid = p.observation_uuid
        WHERE o.quality_grade = 'research'
        ORDER BY random()
        LIMIT ${MAX_RN}
    ) TO '${EXPORT_DIR}/${EXPORT_GROUP}_photos.csv' WITH CSV HEADER DELIMITER E'\t';"
fi

# Create summary of exported data
print_progress "Creating export statistics"
STATS=$(execute_sql "
WITH export_stats AS (
    SELECT 
        COUNT(DISTINCT observation_uuid) as num_observations,
        COUNT(DISTINCT taxon_id) as num_taxa,
        COUNT(DISTINCT observer_id) as num_observers
    FROM ${EXPORT_GROUP}_observations
)
SELECT format(
    'Exported Data Statistics:
    Observations: %s
    Unique Taxa: %s
    Unique Observers: %s',
    num_observations, num_taxa, num_observers
)
FROM export_stats;")

echo "${STATS}" >> "${HOST_EXPORT_DIR}/export_summary.txt"

print_progress "Cladistic filtering complete"

----
Full Path: r1/wrapper.sh

#!/bin/bash

# Setup logging
SCRIPT_DIR="$(dirname "$(readlink -f "$0")")"
LOG_FILE="${SCRIPT_DIR}/$(basename "$0" .sh)_$(date +%Y%m%d_%H%M%S).log"
echo "Starting new run at $(date)" > "${LOG_FILE}"

# Function to log messages to both console and file
log_message() {
    echo "$1" | tee -a "${LOG_FILE}"
}

# Redirect all stdout and stderr to both console and log file
exec 1> >(tee -a "${LOG_FILE}")
exec 2> >(tee -a "${LOG_FILE}")

log_message "Initializing export process with configuration:"

# Database config
export DB_USER="postgres"
export VERSION_VALUE="v0"
export RELEASE_VALUE="r1"
export ORIGIN_VALUE="iNat-Dec2024"
export DB_NAME="ibrida-${VERSION_VALUE}-${RELEASE_VALUE}"
log_message "Database: ${DB_NAME}"
log_message "Version: ${VERSION_VALUE}"
log_message "Release: ${RELEASE_VALUE}"

# Export parameters
export REGION_TAG="NAfull"
export MIN_OBS=50
export MAX_RN=4000
export PRIMARY_ONLY=true
export EXPORT_GROUP="primary_terrestrial_arthropoda"
export PROCESS_OTHER=false
log_message "Region: ${REGION_TAG}"
log_message "Min Observations: ${MIN_OBS}"
log_message "Max Random Number: ${MAX_RN}"
log_message "Export Group: ${EXPORT_GROUP}"

# Paths
export DB_CONTAINER="ibridaDB"
export HOST_EXPORT_BASE_PATH="/datasets/ibrida-data/exports"
export CONTAINER_EXPORT_BASE_PATH="/exports"
export EXPORT_SUBDIR="${VERSION_VALUE}/${RELEASE_VALUE}/primary_only_${MIN_OBS}min_${MAX_RN}max"
export BASE_DIR="/home/caleb/repo/ibridaDB/dbTools/export/v0"
log_message "Export Directory: ${HOST_EXPORT_BASE_PATH}/${EXPORT_SUBDIR}"

# Source common functions
source "${BASE_DIR}/common/functions.sh"

# Execute main script
send_notification "Starting ${EXPORT_GROUP} export"
log_message "Executing main script at $(date)"
"${BASE_DIR}/common/main.sh"

log_message "Process completed at $(date)"
send_notification "${EXPORT_GROUP} export completed!"

----
Full Path: ../../../docker/stausee/docker-compose.yml

services:
  ibrida:
    image: postgis/postgis:15-3.3
    user: "998:998"
    shm_size: '16g'
    environment:
      POSTGRES_PASSWORD: ooglyboogly69
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_SHARED_BUFFERS: 8GB
      POSTGRES_WORK_MEM: 2048MB
      POSTGRES_MAINTENANCE_WORK_MEM: 4GB
    volumes:
      - ~/repo/ibridaDB/dbTools:/tool
      - ~/repo/ibridaDB/dbQueries:/query
      - /database/ibridaDB:/var/lib/postgresql/data
      - /datasets/ibrida-data/exports:/exports
      - /datasets/ibrida-data/intake:/metadata
    ports:
      - "5432:5432"
    container_name: ibridaDB

----
Full Path: ../../../docker/stausee/entrypoint.sh

#!/bin/bash
set -e

# Just log and exit - let Docker's default entrypoint handle PostgreSQL
echo "Entrypoint script executed at $(date)"

